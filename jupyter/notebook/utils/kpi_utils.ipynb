{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the findspark module to help locate and initialize Spark\n",
    "import findspark\n",
    "\n",
    "# Initialize Spark\n",
    "findspark.init()\n",
    "\n",
    "# Import the jupyter_black module, which is an extension to format code cells in Jupyter Notebook\n",
    "import jupyter_black\n",
    "\n",
    "# Load and enable the jupyter_black extension to format code cells automatically\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import desc, col, sum, max, year, current_date, date_sub, avg\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_categories_by_numeric_column(\n",
    "    df: DataFrame, category_column: str, numeric_column: str, n: int\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the top N categories based on a numeric column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame containing data.\n",
    "        category_column (str): The name of the categorical column.\n",
    "        numeric_column (str): The name of the numeric column for ranking.\n",
    "        n (int): The number of top categories to return.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the top N categories based on the numeric column.\n",
    "    \"\"\"\n",
    "    # Group by the categorical column and aggregate the sum of the numeric column\n",
    "    category_aggregated = df.groupBy(category_column).agg(\n",
    "        sum(numeric_column).alias(\"Total_\" + numeric_column)\n",
    "    )\n",
    "\n",
    "    # Sort by total numeric column in descending order and limit to top N\n",
    "    top_n_categories = category_aggregated.sort(desc(\"Total_\" + numeric_column)).limit(\n",
    "        n\n",
    "    )\n",
    "\n",
    "    return top_n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import round, avg, stddev, min, max\n",
    "\n",
    "\n",
    "def get_numeric_column_distribution_by_category(\n",
    "    df: DataFrame, num_col: str, cat_col: str\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate distribution statistics of a numeric column per job category.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with the provided schema.\n",
    "        num_col (str): Name of the numeric column for which distribution is calculated.\n",
    "        cat_col (str): Name of the categorical column used for grouping.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with rounded numeric column distribution statistics per job category.\n",
    "    \"\"\"\n",
    "    # Calculate distribution statistics per job category\n",
    "    distribution = df.groupBy(cat_col).agg(\n",
    "        round(avg(num_col), 2).alias(num_col + \"_Avg\"),\n",
    "        round(stddev(num_col), 2).alias(num_col + \"_StdDev\"),\n",
    "        round(min(num_col), 2).alias(num_col + \"_Min\"),\n",
    "        round(max(num_col), 2).alias(num_col + \"_Max\"),\n",
    "    )\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_salary_per_agency(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the highest salary records within each agency.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with job records.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with the highest salary records per agency.\n",
    "    \"\"\"\n",
    "    # Define a window specification to partition by \"Agency\"\n",
    "    window_spec = Window.partitionBy(\"agency\")\n",
    "\n",
    "    # Calculate the maximum salary within each agency using the window function\n",
    "    df_with_max_salary = df.withColumn(\n",
    "        \"MaxSalary\", max(col(\"annualsalaryto\")).over(window_spec)\n",
    "    )\n",
    "\n",
    "    # Filter rows where the salary matches the maximum salary per agency\n",
    "    result = df_with_max_salary.filter(col(\"annualsalaryto\") == col(\"MaxSalary\"))\n",
    "\n",
    "    # Select the relevant columns for the final result\n",
    "    final_result = result.select(\"job_id\", \"agency\", \"annualsalaryto\")\n",
    "\n",
    "    final_result_sorted = final_result.orderBy(col(\"AnnualSalaryTo\").desc())\n",
    "\n",
    "    return final_result_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_salary_per_agency_last_n_years(\n",
    "    df: DataFrame, n_years: int = 2\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the average annual salary for each agency for job postings in the last N years.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with job records.\n",
    "        n_years (int): Number of years to consider. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the average annual salary per agency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert \"Posting Date\" to date format\n",
    "    df = df.withColumn(\"Posting_Date\", col(\"Posting_Date\").cast(\"date\"))\n",
    "\n",
    "    # Calculate the date N years ago from current date\n",
    "    nyears_ago = date_sub(current_date(), 365 * n_years)\n",
    "\n",
    "    # Filter data for the last N years\n",
    "    filtered_df = df.filter(col(\"Posting_Date\") >= nyears_ago)\n",
    "\n",
    "    # Calculate average annual salary per agency\n",
    "    avg_salary_df = filtered_df.groupBy(\"Agency\").agg(avg(\"AnnualSalaryTo\"))\n",
    "\n",
    "    return avg_salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split, explode, round, avg\n",
    "\n",
    "\n",
    "def calculate_average_salary_by_ngram(\n",
    "    df: DataFrame, ngram_column: str, salary_column: str\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the average salary for different ngrams in the provided column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with job records.\n",
    "        ngram_column (str): Name of the column containing ngrams.\n",
    "        salary_column (str): Name of the column containing salary information.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the average salary per ngram.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the ngram column by comma and create a new column\n",
    "    df = df.withColumn(\"ngrams_list\", split(col(ngram_column), \",\"))\n",
    "\n",
    "    # Explode the ngrams list and select necessary columns\n",
    "    exploded_df = df.select(explode(\"ngrams_list\").alias(\"ngram\"), col(salary_column))\n",
    "\n",
    "    # Calculate average salary per ngram\n",
    "    ngram_avg_salary_df = exploded_df.groupBy(\"ngram\").agg(\n",
    "        round(avg(col(salary_column)), 0).alias(\"avg_salary\")\n",
    "    )\n",
    "\n",
    "    # Sort the result by average salary in descending order\n",
    "    sorted_ngram_avg_salary_df = ngram_avg_salary_df.orderBy(\n",
    "        \"avg_salary\", ascending=False\n",
    "    )\n",
    "\n",
    "    return sorted_ngram_avg_salary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
