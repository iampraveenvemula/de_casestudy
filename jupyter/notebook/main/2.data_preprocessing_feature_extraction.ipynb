{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#1F618D\"> Newyork City Job Postings - Data Engineering Challenge </font>\n",
    "### <font color=\"#F5B041\"> Part-2: Data Preprocessing & Feature Engineering </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run ../utils/prep_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"NYCJobsFeatureEngineering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    \"../../dataset/raw_data/nyc-jobs.csv\", header=True, inferSchema=True, escape='\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#1F618D\"> 1. Feature Extraction - </font> <font color=\"#F5B041\"> Annual Salary </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = standardize_annual_salary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting average annual salary feature\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"AverageAnnualSalary\", (col(\"AnnualSalaryFrom\") + col(\"AnnualSalaryTo\")) / 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+-------------------+\n",
      "|AnnualSalaryFrom|AnnualSalaryTo|AverageAnnualSalary|\n",
      "+----------------+--------------+-------------------+\n",
      "|         42405.0|       65485.0|            53945.0|\n",
      "|         60740.0|      162014.0|           111377.0|\n",
      "|        51907.68|      54580.32|            53244.0|\n",
      "|        51907.68|      54580.32|            53244.0|\n",
      "|         72800.0|       72800.0|            72800.0|\n",
      "+----------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"AnnualSalaryFrom\", \"AnnualSalaryTo\", \"AverageAnnualSalary\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#1F618D\"> 2. Feature Extraction - </font>  <font color=\"#F5B041\"> Degree List & Highest Degree </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all degrees like masters, pg, diploma, baccalaureate, high school etc\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"degrees\",\n",
    "    get_degree_list_udf(df[\"Minimum Qual Requirements\"], lit(build_regex(keywords))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the highest degree from list of degrees\n",
    "\n",
    "df = df.withColumn(\"HighestDegree\", get_highest_degree_udf(col(\"degrees\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------+\n",
      "|degrees                              |HighestDegree|\n",
      "+-------------------------------------+-------------+\n",
      "|[baccalaureate]                      |baccalaureate|\n",
      "|[baccalaureate, high school, diploma]|baccalaureate|\n",
      "|[high school]                        |high school  |\n",
      "|[high school]                        |high school  |\n",
      "+-------------------------------------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"degrees\", \"HighestDegree\").show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#1F618D\"> 3. Feature Extraction - </font>  <font color=\"#F5B041\"> Skills as ngrams</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove junk characters\n",
    "cleaned_df = preprocess_text_column(\n",
    "    df, input_column=\"Preferred SKills\", output_column=\"cleaned_text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text & remove stop words\n",
    "filtered_df = tokenize_and_remove_stopwords(\n",
    "    cleaned_df, input_column=\"cleaned_text\", output_column=\"filtered_words\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply lemmatization using the UDF\n",
    "lemmatized_df = apply_lemmatization(\n",
    "    filtered_df, input_column=\"filtered_words\", output_column=\"lemmatized_words\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract n-grams\n",
    "ngram_df = extract_ngrams(\n",
    "    lemmatized_df, input_column=\"lemmatized_words\", output_column=\"ngrams\", n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#1F618D\"> 3. Feature Selection & </font>  <font color=\"#F5B041\"> Data Serialization </font>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the columns which are not required for kpi analysis\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"Civil Service Title\",\n",
    "    \"Title Code No\",\n",
    "    \"Level\",\n",
    "    \"Full-Time/Part-Time indicator\",\n",
    "    \"Salary Range From\",\n",
    "    \"Salary Range To\",\n",
    "    \"Salary Frequency\",\n",
    "    \"Work Location\",\n",
    "    \"Division/Work Unit\",\n",
    "    \"Job Description\",\n",
    "    \"Minimum Qual Requirements\",\n",
    "    \"Preferred Skills\",\n",
    "    \"Additional Information\",\n",
    "    \"To Apply\",\n",
    "    \"Hours/Shift\",\n",
    "    \"Work Location 1\",\n",
    "    \"Recruitment Contact\",\n",
    "    \"Residency Requirement\",\n",
    "    \"Post Until\",\n",
    "    \"Posting Updated\",\n",
    "    \"Process Date\",\n",
    "    \"cleaned_text\",\n",
    "    \"words\",\n",
    "    \"filtered_words\",\n",
    "    \"lemmatized_words\",\n",
    "]\n",
    "\n",
    "ngram_df = ngram_df.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory path\n",
    "target_directory = \"../../dataset/processed_data/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with invalid characters\n",
    "columns_with_valid_names = [\n",
    "    col.replace(\" \", \"_\").replace(\"-\", \"_\").lower() for col in ngram_df.columns\n",
    "]\n",
    "ngram_df_renamed = ngram_df.toDF(*columns_with_valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array column to comma-separated string to persist\n",
    "ngram_df_renamed = ngram_df_renamed.withColumn(\"ngrams\", concat_ws(\",\", col(\"ngrams\")))\n",
    "ngram_df_renamed = ngram_df_renamed.withColumn(\n",
    "    \"degrees\", concat_ws(\",\", col(\"degrees\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Posting Date\" to date format\n",
    "ngram_df_renamed = ngram_df_renamed.withColumn(\n",
    "    \"Posting_Date\", col(\"Posting_Date\").cast(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df_renamed.coalesce(1).write.mode(\"overwrite\").format(\"parquet\").save(\n",
    "    \"../../dataset/processed_data/nyc_job_postings_processed_data.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df_renamed.coalesce(1).write.mode(\"overwrite\").format(\"csv\").option(\n",
    "    \"sep\", \"\\t\"\n",
    ").save(\"../../dataset/processed_data/nyc_job_postings_processed_data.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x 1 root root 512 Aug 31 15:42 nyc_job_postings_processed_data.csv\r\n",
      "drwxr-xr-x 1 root root 512 Aug 31 15:41 nyc_job_postings_processed_data.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../dataset/processed_data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
